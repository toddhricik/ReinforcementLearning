{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Environment: Gridwolrd</h2>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Gridwolrd environemnt is composed of a class containing the maze itself, the possible actions allowed within the environment and helpoer functions to compute rewards and transition probabilties of the possible moves available. See the [Gridworld environment class notebook](envGridworld.ipynb) for details of this class. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/gridworld_grid.png\" style=\"display:block; margin:auto\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Environment Gridworld: Maze</h3>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maze is represented as a 20x20 numpy array of integers where each elelment of the 2D array represents a position in the maze and the value of each element signifies whether the position can be occupied by the agent (i.e. $maze[i,j]=0$) or if the position is a wall (i.e. $maze[i,j]=-1$)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\large maze[i,j]\n",
    "= \n",
    "\\begin{cases}\n",
    "0\\quad\\quad \\,\\,\\,\\,\\,\\,maze[i,j]\\normalsize\\text{ is not a wall } \\\\\n",
    "-1\\quad\\,\\,\\,\\,\\,\\,\\,\\,maze[i,j]\\normalsize\\text{ is a wall}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Environment Gridworld: Mask</h3>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Gridworld class contains a data member mask which is an $nxm$ numpy array that is passed to helper functions in [helpers.ipynb](helpers.ipynb) which plot the state values and policies."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\large mask[i,j]\n",
    "= \n",
    "\\begin{cases}\n",
    "False\\quad\\quad maze[i,j]\\normalsize \\text{ is not a wall } \\\\\n",
    "True\\quad\\,\\, \\,\\,\\,\\,\\,\\,maze[i,j]\\normalsize\\text{ is a wall}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Environment Gridworld: States</h3>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each white square in the maze represents a state which is a random variable which we denote as $S$.<br> Each observed state $s\\in S$ is defined as an ordered pair $(x,y)$ which represents the position of the agent on the grid.\n",
    "$$\\large S\\coloneqq\\{(x, y): (x\\in\\mathbb{Z}) \\cap (0\\le x<n) \\bigcap (y\\in\\mathbb{Z}) \\cap (0\\le y<m)\\}$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Environment Gridworld: Actions</h3>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each action is a random variable which we denote with the symbol $A$ and there are four actions available to the agent.<br>\n",
    "$$\\large A\\coloneqq\\{Up, Down, Left, Right\\}$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Environment Gridworld: Rewards</h3>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At each time step the reward of an action taken is either -1 or 0 depending upon whether the next state is a finish line or non-finish line square on the grid. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\large R_t\n",
    "= \n",
    "\\begin{cases}\n",
    "0\\quad\\quad \\Large s_{t+1}\\normalsize =\\text{ finish line square on the grid } \\\\\n",
    "-1\\quad\\, \\Large s_{t+1}\\normalsize\\neq\\text{ finish line square on the grid}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Environment Gridworld: Transitions</h3>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transition probabilities used by the Gridwold environment assume that the probability of moving to the next state (i.e. square in the maze) given any any action $a \\in A$ from any current state $s \\in S$ is equal to 1. More simply there is only one possible next state $s' \\in S$ for each action $a \\in A$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large P(S_{t+1}=s_{t+1}|S_t=s_t, A=a_t) = 1 \\qquad \\forall \\,s_{t+1}, s_t \\in S,\\, a_t \\in A$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import import_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class envGridworld:\n",
    "    def __init__(self, path_to_maze, finish_position):\n",
    "        \n",
    "        # load maze from numpy file\n",
    "        self._maze = np.load(path_to_maze, mmap_mode='r')\n",
    "        \n",
    "        # Mask maze walls (indicated by -1) for seaborn heatmap in helper funciton plot_values\n",
    "        self._mask = (self._maze == -1)\n",
    "        \n",
    "        i, j = finish_position\n",
    "        # If finish position is valid (i.e. not a wall and within the grid boundary limits),\n",
    "        # then set the final position\n",
    "        if ( (self._maze[i, j] != -1) and (i >= 0) and (i < self._maze.shape[0]) and (j >= 0) and (j < self._maze.shape[1]) ):\n",
    "            self._finish_position = tuple((i, j))\n",
    "         \n",
    "        # Define the four actions available to choose from in the environment\n",
    "        self._actions = (\"up\", \"down\", \"left\", \"right\")\n",
    "        \n",
    "        # Create a 2D matrix of tuples representing the states (i.e. squares on the gird)\n",
    "        self._states = np.zeros((self._maze.shape[0], self._maze.shape[1], 2), dtype=np.int32)\n",
    "        for i in np.arange(self._maze.shape[0]):\n",
    "            for j in np.arange(self._maze.shape[1]):\n",
    "                self._states[i,j] = np.array((i,j))\n",
    "        \n",
    "    def reward(self, state, next_state):\n",
    "        # Each step towards the finsih square has a reward of -1\n",
    "        # Moving to the finish line square has a reward of 0\n",
    "        if (next_state != self._finish_position):\n",
    "            return -1\n",
    "        return 0\n",
    "\n",
    "    # This is the conditional probability of the reward and next state given the current state and action\n",
    "    def p_sp_r_given_s_a(self, next_state, reward, state, action):\n",
    "        return 1.0\n",
    "\n",
    "    # This function returns the next state after choosing an action from the current state\n",
    "    # after checking to see if the action would result in hitting a maze wall or falling off\n",
    "    # of the grid. In either scenario the next state is reset to the current state\n",
    "    def transitions(self, state, action):\n",
    "        if (action == 0):\n",
    "            next_state = (state[0]-1, state[1])\n",
    "            # Hit the upper boundary of the maze or hit wall from below\n",
    "            if (state[0] == 0 or self._maze[state[0]-1, state[1]] == -1):\n",
    "                next_state = state\n",
    "        if (action == 1):\n",
    "            next_state = (state[0]+1, state[1])\n",
    "            # Hit the bottom boundary of the maze or hit a wall from above\n",
    "            if (state[0] == self._maze.shape[0]-1 or self._maze[state[0]+1, state[1]] == -1):\n",
    "                next_state = state\n",
    "        if (action == 2):\n",
    "            next_state = (state[0], state[1]-1)\n",
    "            # Hit the left boundary of maze or hit a wall from the right\n",
    "            if (state[1] == 0 or self._maze[state[0], state[1]-1] == -1):\n",
    "                next_state = state\n",
    "        if (action == 3):\n",
    "            next_state = (state[0], state[1]+1)            \n",
    "            # Hit the right boundary of maze or hit a wall from the left\n",
    "            if (state[1] == self._maze.shape[1]-1 or self._maze[state[0], state[1]+1] == -1):\n",
    "                next_state = state\n",
    "        r = self.reward(state, next_state)\n",
    "        p = self.p_sp_r_given_s_a(next_state, r, state, action)\n",
    "        return next_state, r, p\n",
    "    \n",
    "    # Getters and setters via property decorators\n",
    "    @property\n",
    "    def finish_position(self):\n",
    "        return self._finish_position\n",
    "    @finish_position.setter\n",
    "    def finish_position(self, finish_position):\n",
    "        i, j = finish_position\n",
    "        print((i,j))\n",
    "        if (self._maze[i,j] == -1):\n",
    "            raise Exception(\"Tuple finish position is a wall in the maze\")\n",
    "            #print(\"Please choose a position that does not represent a wall in the maze\")\n",
    "        if(i < 0 or i > self._maze.shape[0] -1 or j < 0 or j > self._maze.shape[1]-1):\n",
    "            raise Exception(\"Tuple finish_position is not valid\")\n",
    "        self._finish_position = tuple((i, j))\n",
    "        return\n",
    "    @property\n",
    "    def States(self):\n",
    "        return self._states\n",
    "    @property\n",
    "    def Actions(self):\n",
    "        return self._actions\n",
    "    @property\n",
    "    def Maze(self):\n",
    "        return self._maze\n",
    "    @property\n",
    "    def Mask(self):\n",
    "        return self._mask"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Instantiate a Gridworld object</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a finsih position\n",
    "#fin_position = (0,4)\n",
    "\n",
    "# Instantiate a Gridworld object\n",
    "#ex_gridworld = envGridworld(path_to_maze='./maze2.npy', finish_position=fin_position)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the maze data member\n",
    "#ex_gridworld.Maze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the maze actions available\n",
    "#ex_gridworld.Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set and get the finish lize position on the grid\n",
    "#ex_gridworld.finish_position = (0,0)\n",
    "#ex_gridworld.finish_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the maze mask\n",
    "#ex_gridworld.Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the gridworld object\n",
    "#del ex_gridworld"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic_python_3_9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "56a450c7dfd4e5ec1e847f4263cc8e8bcabd06d76b9dab54510bb1f50cf86976"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
